from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
import os
from dotenv import load_dotenv
from intention import IntentionRecognizer
load_dotenv(r"è¯¾ç¨‹åŠ©æ‰‹/lna.env")
from my_tools import ToolManager
from rag_process import RAGProcess
import uuid
from history_management import HistoryManager
class AgentRouter:
    # ç±»å˜é‡ï¼Œå­˜å‚¨æ‰€æœ‰ä¼šè¯çš„å†å²
    store = {}
    intent_recognizer = IntentionRecognizer()#æ„å›¾è¯†åˆ«
    my_rag = RAGProcess()
    intention=''
    def __init__(self, session_id:str):
        self.session_id = session_id if session_id else str(uuid.uuid4())
        self.llm = ChatOpenAI(
            model="qwen-max",
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
            streaming=True
        )

        # 1. å®šä¹‰å„ç§ Prompt
        self.prompts = {
            "normal": ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„èŠå¤©åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·çš„æé—®å’Œå†å²å¯¹è¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œ
                 å¦‚æœå†å²å¯¹è¯ä¸­çš„ä¿¡æ¯èƒ½å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä½ éœ€è¦ä½¿ç”¨å†å²å¯¹è¯ä¸­çš„ä¿¡æ¯ã€‚
                 å¦‚æœå›ç­”ä¸äº†ç”¨æˆ·é—®é¢˜è¯·ä¸€å®šè¦æŒ‰ç…§ä¸‹é¢æç¤ºå›ç­”ç”¨æˆ·ï¼š
                 1.å½“ç”¨æˆ·çš„é—®é¢˜æ¶‰åŠå®æ—¶ä¿¡æ¯æˆ–è€…éœ€è¦è”ç½‘æœç´¢æ—¶ï¼Œä½ éœ€è¦æé†’ç”¨æˆ·åˆ‡æ¢æ¨¡å¼ï¼Œå¦‚ï¼šè¯·é€‰æ‹©è”ç½‘æœç´¢æ¨¡å¼ï¼Œæˆ‘å°†ä¸ºæ‚¨æœç´¢ç›¸å…³ä¿¡æ¯ã€‚
                 2.å½“ç”¨æˆ·é—®é¢˜æ¶‰åŠåˆ°è¯¾ç¨‹ç›¸å…³å†…å®¹æ—¶ï¼Œä½ éœ€è¦æé†’ç”¨æˆ·åˆ‡æ¢æ¨¡å¼ï¼Œå¦‚ï¼šè¯·é€‰æ‹©è¯¾ç¨‹å’¨è¯¢æ¨¡å¼ï¼Œæˆ‘å°†ä¸ºæ‚¨æŸ¥è¯¢ç›¸å…³è¯¾ç¨‹å†…å®¹ã€‚
                 3.å½“ç”¨æˆ·æåŠä¸Šä¼ çš„æ–‡ä»¶å†…å®¹æ—¶ï¼Œä½ éœ€è¦æé†’ç”¨æˆ·è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼Œå¦‚ï¼šè¯·é€‰æ‹©ä¸Šä¼ æ–‡ä»¶æ¨¡å¼å¹¶ä¸Šä¼ æ–‡ä»¶ï¼Œæˆ‘æ‰èƒ½ä¸ºæ‚¨æŸ¥è¯¢æ–‡ä»¶å†…å®¹ã€‚
                 ä¸‰ä¸ªæ¨¡å¼åç§°ä¸èƒ½æ”¹å˜ï¼Œå…¶ä»–è¯æœ¯å¯ä»¥éšæœºåº”å˜ã€‚
                 """),
                MessagesPlaceholder(variable_name="chat_history"),
                ("user", "{input}"),
            ]),
            "search": ChatPromptTemplate.from_template("""
                ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·é«˜æ•ˆå®Œæˆå„ç§ä»»åŠ¡ã€‚ä½ æ‹¥æœ‰ä»¥ä¸‹å¼ºå¤§çš„å·¥å…·èƒ½åŠ›ï¼š
                {tools}  # â† å¿…é¡»æ·»åŠ ï¼šå·¥å…·åˆ—è¡¨ï¼ˆç”± LangChain è‡ªåŠ¨æ³¨å…¥ï¼‰
                å¯ç”¨å·¥å…·åç§°ï¼š{tool_names}  # â† å¿…é¡»æ·»åŠ ï¼šå·¥å…·ååˆ—è¡¨
                ## ğŸ” å·¥å…·ä½¿ç”¨æŒ‡å—
                **æœç´¢ä¿¡æ¯æ—¶ï¼š**
                - æœ€æ–°æ–°é—»ã€å®æ—¶ä¿¡æ¯ â†’ ä½¿ç”¨ `search_tool`
                - ç‰¹å®šç½‘é¡µå†…å®¹ â†’ ä½¿ç”¨ `web_scraping`
                **æ—¶é—´å¤„ç†æ—¶ï¼š**
                - è·å–å½“å‰æ—¶é—´ã€æ—¥æœŸè®¡ç®— â†’ ä½¿ç”¨ `datetime_operations`
                **å¤©æ°”æŸ¥è¯¢æ—¶ï¼š**
                - å®æ—¶å¤©æ°” â†’ ä½¿ç”¨ `get_realtime_weather`

                è¯·ä½¿ç”¨ ReAct æ ¼å¼è¿›è¡Œæ€è€ƒå’Œè¡ŒåŠ¨ï¼š
                Thought: ä½ åº”è¯¥æ€è€ƒæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
                Action: å·¥å…·åç§°ï¼ˆå¿…é¡»æ˜¯ [{tool_names}] ä¸­çš„ä¸€ä¸ªï¼‰
                Action Input: å·¥å…·çš„è¾“å…¥å‚æ•°
                Observation: å·¥å…·æ‰§è¡Œåçš„ç»“æœ
                ...ï¼ˆå¯ä»¥é‡å¤ï¼‰
                Thought: æˆ‘ç°åœ¨å¯ä»¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆäº†
                Final Answer: è¿”å›ç»™ç”¨æˆ·çš„æœ€ç»ˆå›ç­”


                chat_history: {chat_history}
                Question: {input}
                Thought:{agent_scratchpad}
                """),
        }

        # 2. åˆ›å»ºå„ç§å·¥å…·å’Œæ‰§è¡Œå™¨
        self.tools = ToolManager().get_tools()
        self.agent_executor = self._create_agent_executor()
        # 3. åˆ›å»º RunnableWithMessageHistory ç”¨äº Agent
        self.agent_with_history = RunnableWithMessageHistory(
            self.agent_executor,
            get_session_history=self.get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
        )
        #ä»æœ¬åœ°åŠ è½½å¯¹è¯è®°å½•
        self.history = self.get_session_history(self.session_id)
        for item in HistoryManager().get_solo_history(self.session_id):
            self.history.add_user_message(item['user_question'])
            self.history.add_ai_message(item['ai_response'])

    def _create_agent_executor(self):
        agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompts["search"],
        )
        return AgentExecutor(agent=agent, tools=self.tools, verbose=False,handle_parsing_errors=True)

    def get_session_history(self, session_id):
        if session_id not in self.store:
            self.store[session_id] = InMemoryChatMessageHistory()
        return self.store[session_id]

    def _handle_normal_stream(self, input_dict: dict):#2.0ç‰ˆæœ¬
        """å¤„ç†æ™®é€šå¯¹è¯"""
        history = self.get_session_history(self.session_id)
        # å…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        history.add_user_message(input_dict["input"])
        chain = self.prompts["normal"] | self.llm
        response = ""
        for chunk in chain.stream({
            "input": input_dict["input"],
            "chat_history": history.messages
        }):
            content = chunk.content
            if content:
                response += content
                yield content  
        history.add_ai_message(response)

    def _handle_search_stream(self, input_dict: dict):
        """å¤„ç†è”ç½‘æœç´¢"""
        config = {"configurable": {"session_id": self.session_id}}
        # ä½¿ç”¨ stream æ¨¡å¼
        # try:
        for event in self.agent_with_history.stream(
            {"input": input_dict["input"]},
            config=config
        ):
            #è°ƒè¯•ï¼šæ‰“å° event ç»“æ„ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æ‰“å¼€ï¼‰
            print(f"Event keys: {list(event.keys())}")
            print(f"Event: {event}")

            # 1. åˆ¤æ–­æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨å¼€å§‹ï¼šæ£€æŸ¥ 'actions' å­—æ®µ
            if "actions" in event and event["actions"]:
                action = event["actions"][0]
                tool_name = getattr(action, "tool", "æœªçŸ¥å·¥å…·")
                yield f"\nğŸ” æ­£åœ¨è°ƒç”¨å·¥å…·ï¼š{tool_name}\n"
                continue

            # 2. åˆ¤æ–­æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨ç»“æŸï¼šæ£€æŸ¥ 'steps' ä¸­çš„ Observation
            if "steps" in event and event["steps"]:
                step = event["steps"][0]
                if hasattr(step, "tool_output") or hasattr(step, "observation"):
                    result=step.observation
                    # print(f"æŸ¥è¯¢ç»“æœï¼š{result}")
                    yield "âœ… å·²è·å–æœç´¢ç»“æœï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...\n\n"
                continue                   
            # 3. åˆ¤æ–­æ˜¯å¦æ˜¯ LLM ç”Ÿæˆä¸­ï¼šæ£€æŸ¥ 'messages' ä¸­çš„ AIMessageChunk
            if "output" in event:
                result = event["output"]
                prompt = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„åŠ©æ‰‹ï¼Œä½ éœ€è¦ä¸€å­—ä¸è½çš„å®Œæ•´å¤è¿°ç”¨æˆ·çš„å†…å®¹ï¼Œä¸å…è®¸å¢åŠ æˆ–å‡å°‘æˆ–ä¿®æ”¹ä»»ä½•å†…å®¹ã€‚"),
                ("user", "{input}"),
                ])
                chain = prompt | self.llm
                for chunk in chain.stream({"input": result}):
                    yield chunk.content
        # except Exception as e:
        #     yield f"\nâŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        
    
    def _handle_rag_stream(self, input_dict: dict):
        """å¤„ç†RAGæµå¼è¾“å‡ºï¼ˆè¿™é‡Œéœ€è¦ä½ é›†æˆä½ çš„å‘é‡æ•°æ®åº“ï¼‰"""
        answer = self.my_rag.answer_question(input_dict['input'],self.session_id,'course')
        for chunk in answer:
            if chunk["type"] == "rag":
                yield chunk["content"]
            if chunk["type"] == "answer":
                yield chunk["answer"]
    
    
    def _handle_upload_stream(self, input_dict: dict):
        """å¤„ç†æ–‡ä»¶ä¸Šä¼ æµå¼è¾“å‡º"""
        upload_files = input_dict.get("upload") if input_dict.get("upload") else []
        len_files = len(upload_files)
        for index,doc in enumerate(upload_files):
            yield f"æ­£åœ¨ä¸Šä¼ ç¬¬{index+1}/{len_files}ä¸ªæ–‡ä»¶\n"
            upload_result = self.my_rag.upload_document(doc,self.session_id)
            yield upload_result['message'] + '\n'
        if not self.my_rag.get_user_documents(self.session_id):
            yield "è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼\n"
            return
        answer = self.my_rag.answer_question(input_dict['input'], self.session_id, 'user')
        for chunk in answer:
            if chunk['type'] == 'answer':
                yield chunk['answer']
            # elif chunk['type'] == 'sources':
            #     yield chunk['sources']              
        # yield "æµå¼ä¼ è¾“æµ‹è¯•ä¸­\n"

    def chat_stream(self,input_dict:dict):
        """
        ç»Ÿä¸€çš„èŠå¤©å…¥å£ï¼Œæ”¯æŒæµå¼è¾“å‡ºï¼ˆè¿”å›ç”Ÿæˆå™¨ï¼‰
        """
        # 1. è¯†åˆ«æ„å›¾
        intent = input_dict["intention"]
        self.intention = intent
        print(f"[DEBUG] æ„å›¾è¯†åˆ«ä¸º: {intent}")
        
        # 2. æ ¹æ®æ„å›¾è°ƒç”¨å¯¹åº”çš„å¤„ç†å‡½æ•°ï¼ˆæµå¼ï¼‰
        if intent == "normal":
            # âœ… ä½¿ç”¨ yield from æŠŠ _handle_normal çš„æ¯ä¸ª token é€ä¼ å‡ºå»
            yield from self._handle_normal_stream({"input": input_dict["message"]})

        elif intent == "search":
            # è¿™é‡Œå¯ä»¥å…ˆ yield "æ­£åœ¨æœç´¢..."ï¼Œå†æµå¼è¿”å›æœ€ç»ˆç­”æ¡ˆ
            # yield "æ­£åœ¨è”ç½‘æŸ¥è¯¢..."
            yield from self._handle_search_stream({"input": input_dict["message"]})

        elif intent == "rag":
            # yield "æ­£åœ¨ä»çŸ¥è¯†åº“æŸ¥æ‰¾ä¿¡æ¯...\n"           
            yield from self._handle_rag_stream({"input": input_dict["message"]})

        elif intent == "upload":
            yield "æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œè¯·ç¨ç­‰...\n"
            yield from self._handle_upload_stream({"input": input_dict["message"],"upload":input_dict["upload"]})

        else:
            yield from self._handle_normal_stream({"input": input_dict["message"]})


if __name__ == "__main__":
    router = AgentRouter("lna01")
    while True:
        user_input = input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
        if user_input.lower() in ["é€€å‡º", "quit", "exit"]:
            break       
        print("åŠ©æ‰‹å›å¤: ")
        # âœ… æ­£ç¡®æ–¹å¼ï¼šéå†ç”Ÿæˆå™¨ï¼Œé€ä¸ªæ¥æ”¶ token
        for token in router.chat_stream({"intention": "normal", "message": user_input, "upload": None}):
            print(token, end="", flush=True)  # å®æ—¶æ‰“å°ï¼Œä¸å¸¦æ¢è¡Œ
        print()  # å›ç­”ç»“æŸåæ¢è¡Œ
        
# if __name__ == "__main__":
#     router = AgentRouter("lna01")
#     while True:
#         user_input = input("\nè¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
#         if user_input.lower() in ["é€€å‡º", "quit", "exit"]:
#             break
#         try:
#             print("åŠ©æ‰‹å›å¤: ", end="", flush=True)
#             # âœ… æ­£ç¡®æ–¹å¼ï¼šéå†ç”Ÿæˆå™¨ï¼Œé€ä¸ªæ¥æ”¶ token
#             for token in router.chat_stream(user_input, upload=None):
#                 print(token, end="", flush=True)  # å®æ—¶æ‰“å°ï¼Œä¸å¸¦æ¢è¡Œ
#             print()  # å›ç­”ç»“æŸåæ¢è¡Œ
#         except Exception as e:
#             print(f"\nå‘ç”Ÿé”™è¯¯: {e}\n")
        